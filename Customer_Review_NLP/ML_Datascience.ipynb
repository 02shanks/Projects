{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddda4226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1E5ZR1Z4OQJG\", \"asin\": \"1495329321\", \"reviewerName\": \"Pure Jonel \\\"Pure Jonel\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\", \"overall\": 4.0, \"summary\": \"An amazing first novel\", \"unixReviewTime\": 1396137600, \"reviewTime\": \"03 30, 2014\"}\n",
      "\n",
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'books_small.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        \n",
    "               \n",
    "        # print(line[reviewText]).....want to print just review but this is json file so need to use related syntax..cant use like dictionary\n",
    "        #just getting review part from 1st dataset\n",
    "        \n",
    "        review = json.loads(line)\n",
    "        \n",
    "        print(review['reviewText'])\n",
    "        print(review['overall'])\n",
    "        \n",
    "                \n",
    "        \n",
    "        break  #just printing 1st stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6019f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('With the government knowing this could happen and not telling anyone then this is a good story of what would happen if an emp attack happened.',\n",
       " 5.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=[]\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "#         print(line)\n",
    "        \n",
    "        review = json.loads(line)\n",
    "        \n",
    "#         print(review['reviewText'])\n",
    "#         print(review['overall'])\n",
    "\n",
    "# creating lists of reviews and overall ratings\n",
    "        reviews.append((review['reviewText'], review['overall']))\n",
    "    \n",
    "    \n",
    "reviews[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ae17f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing juts review[0],score[1]\n",
    "print(reviews[4][1])\n",
    "reviews[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87af168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way \n",
    "\n",
    "class Sentiment:\n",
    "    \n",
    "    NEGATIVE = 'NAGATIVE'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "class Review:\n",
    "    \n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score==3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: # score 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf08bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way contd\n",
    "\n",
    "reviews=[]\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        \n",
    "        review = json.loads(line)\n",
    "\n",
    "\n",
    "        # creating lists of reviews and overall ratings\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "reviews[5].text    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f1e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[5].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940c15ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2460d01",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce451d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split() #press shift+tab to see how to use syntax\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfc7e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 670)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf04178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(training[0].sentiment)\n",
    "training[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ed55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting review(for training model) as text and sentiment in array format from training data set i.e (1-0.33)% of original data\n",
    "\n",
    "train_x= [x.text for x in training]\n",
    "train_y= [x.sentiment for x in training]\n",
    "\n",
    "# collecting review as text and sentiment in array format from test data set\n",
    "\n",
    "test_x= [x.text for x in test]\n",
    "test_y= [x.sentiment for x in test]\n",
    "\n",
    "\n",
    "# train_x[0] \n",
    "# train_y[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc9c9a",
   "metadata": {},
   "source": [
    "## BAG OF WORD METHOD\n",
    "\n",
    "#### Bag of word vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf72f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# see bag of word doc on google for better understanding\n",
    "#also countvectorizer doc \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit a vectorizer to training data and transform training data to give train_x_vector... u can do this in 2 diff steps(see below)\n",
    "train_x_vectors= vectorizer.fit_transform(train_x)  # we get matrix of 670x7372 ... 670 rows corresponds to test dataset\n",
    "\n",
    "test_x_vectors= vectorizer.transform(test_x) #we dont want to fit just tranform becoz this is test data\n",
    "\n",
    "# another way\n",
    "\n",
    "# vectorizer.fit(train_x)\n",
    "# tain_x_vectors= vectorizer.transform(train_x)\n",
    "\n",
    "print(train_x[0]) #text form\n",
    "print(train_x_vectors[0].toarray()) #array form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18593bb",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8090a2",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfb288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See related doc on google\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel = 'linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y) # we pass in x,y to fit this classifier to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53be73e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\",\n",
       " <1x7372 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 36 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0], test_x_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c801cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbff4ff",
   "metadata": {},
   "source": [
    "###### MORE METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dc864",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53cf6802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926e6bc",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c17733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.todense(), train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0].todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdc478",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "224269ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BLOODYPROF\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205557d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd145972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.7515151515151515\n",
      "0.8121212121212121\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# See doc for .score ...pres shift+tab\n",
    "\n",
    "#Mean accuracy\n",
    "\n",
    "print(clf_svm.score(test_x_vectors, test_y))# give accuracy of your prediction\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.todense(), test_y)) # .todense() see in doc\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a58fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91319444 0.21052632 0.22222222]\n",
      "[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "#F1 scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None , labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE, ]))\n",
    "\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None , labels=[Sentiment.POSITIVE,Sentiment.NEUTRAL,Sentiment.NEGATIVE, ]))\n",
    "\n",
    "\n",
    "\n",
    "### this shows good prediction power of postive data but worst prediction in case of negative and neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9e19b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "47\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "## finding/improving on negative ,neutral side\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.NEUTRAL))\n",
    "\n",
    "#training dataset is biased towards positive side\n",
    "#We need to balance positive and negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9996e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
